{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.io import arff\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eer_from_paper(labels, prediction):\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fprs, tprs, _ = roc_curve(labels, prediction)\n",
    "    eer = fprs[np.nanargmin(np.absolute((1 - tprs) - fprs))]\n",
    "    print(eer)\n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eer_changjiang(labels, prediction):\n",
    "    from scipy.optimize import brentq\n",
    "    from scipy.interpolate import interp1d\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, _ = roc_curve(labels, prediction)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eer(y_true, y_score):\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=True)\n",
    "    abs_diff = [abs(fp-tp) for fp, tp in zip(fpr, tpr)]\n",
    "    min_idx = abs_diff.index(min(abs_diff))\n",
    "    eer = (fpr[min_idx] + tpr[min_idx])/2\n",
    "    print(abs_diff, eer)\n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_dropped = []\n",
    "for n in ['X', 'Y', 'Z']:\n",
    "    columns_to_be_dropped.append(f'\"{n}VAR\"')\n",
    "    for i in range(13):\n",
    "        columns_to_be_dropped.append(f'\"{n}MFCC{i}\"')\n",
    "for n in combinations(['X', 'Y', 'Z'], 2):\n",
    "    columns_to_be_dropped.append(f'\"{\"\".join(n)}COS\"')\n",
    "    columns_to_be_dropped.append(f'\"{\"\".join(n)}COR\"')\n",
    "\n",
    "sensors = [\"phone_accel\", \"watch_accel\", \"phone_gyro\", \"watch_gyro\"]\n",
    "activities = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "              'I', 'J', 'K', 'L', 'M', 'O', 'P', 'Q', 'R', 'S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_dataframe(raw: pd.DataFrame, cols_to_drop: list[str]) -> pd.DataFrame:\n",
    "    result = raw.drop(columns=cols_to_drop)\n",
    "    result.columns = [col.replace('\"', \"\") for col in result]\n",
    "    result['ACTIVITY'] = result['ACTIVITY'].str.decode('utf-8')\n",
    "    result['class'] = result['class'].str.decode('utf-8')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_impostors(guid: str, people: list[dict[str, pd.DataFrame]]) -> list[dict[str, pd.DataFrame]]:\n",
    "    return random.choices([i for i in people if i['guid'] != guid], k=18)\n",
    "\n",
    "\n",
    "def biometric_train_test_split(person, impostors, activity, sensors):\n",
    "    full_person = person[sensors[0]].query(f\"`ACTIVITY`=='{activity}'\").drop(\n",
    "        columns=['ACTIVITY', 'class']).add_suffix(sensors[0])\n",
    "    full_set_impostors = [impostors[i][sensors[0]].query(f\"`ACTIVITY`=='{activity}'\").drop(\n",
    "        columns=['ACTIVITY', 'class'])[:3].add_suffix(sensors[0]) for i in range(len(impostors))]\n",
    "\n",
    "    for i in range(1, len(sensors)):\n",
    "        full_person = full_person.merge(person[sensors[i]].query(f\"`ACTIVITY`=='{activity}'\").drop(\n",
    "            columns=['ACTIVITY', 'class']).add_suffix(sensors[i]), left_index=True, right_index=True)\n",
    "        for j in range(len(impostors)):\n",
    "            full_set_impostors[j] = full_set_impostors[j].merge(impostors[j][sensors[i]].query(f\"`ACTIVITY`=='{activity}'\").drop(\n",
    "                columns=['ACTIVITY', 'class'])[:3].add_suffix(sensors[i]), left_index=True, right_index=True)\n",
    "\n",
    "    full_person['class'] = True\n",
    "    for i in range(len(full_set_impostors)):\n",
    "        full_set_impostors[i]['class'] = False\n",
    "\n",
    "    training_set = pd.concat([full_person[:len(\n",
    "        full_person)//2]] + full_set_impostors[:len(full_set_impostors)//2])\n",
    "    testing_set = pd.concat([full_person[len(full_person)//2:]] +\n",
    "                            full_set_impostors[len(full_set_impostors)//2:])\n",
    "\n",
    "    return training_set, testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_classification_df_builder(people: list[dict[str, int | pd.DataFrame]], sensors: list[str]) -> pd.DataFrame:\n",
    "    result_df: pd.DataFrame = None\n",
    "    for person in people:\n",
    "        df: pd.DataFrame = None\n",
    "        for sensor in sensors:\n",
    "            df = person[sensor].drop(columns=['class']).add_suffix(sensor) if df is None else df.merge(\n",
    "                person[sensor].drop(columns=['class']).add_suffix(sensor), left_index=True, right_index=True)\n",
    "            df = pd.get_dummies(df)\n",
    "        df['class']=person['guid']\n",
    "        result_df = df if result_df is None else pd.concat([result_df, df])\n",
    "    return result_df.dropna()\n",
    "\n",
    "def activity_classification_df_builder(people: list[dict[str, int | pd.DataFrame]], sensors: list[str]) -> pd.DataFrame:\n",
    "    result_df: pd.DataFrame = None\n",
    "    for person in people:\n",
    "        df: pd.DataFrame = None\n",
    "        for sensor in sensors:\n",
    "            df = person[sensor].drop(columns=['class','ACTIVITY']).add_suffix(sensor) if df is None else df.merge(\n",
    "                person[sensor].drop(columns=['class','ACTIVITY']).add_suffix(sensor), left_index=True, right_index=True)\n",
    "        result_df = df if result_df is None else pd.concat([result_df, df])\n",
    "    return result_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "people: list[dict[str, pd.DataFrame]] = [{\n",
    "    'guid': i,\n",
    "    'phone_accel': processed_dataframe(pd.DataFrame(arff.loadarff(f\"arff_files/phone/accel/data_{i}_accel_phone.arff\")[0]), columns_to_be_dropped),\n",
    "    'phone_gyro': processed_dataframe(pd.DataFrame(arff.loadarff(f\"arff_files/phone/gyro/data_{i}_gyro_phone.arff\")[0]), columns_to_be_dropped),\n",
    "    'watch_accel': processed_dataframe(pd.DataFrame(arff.loadarff(f\"arff_files/watch/accel/data_{i}_accel_watch.arff\")[0]), columns_to_be_dropped),\n",
    "    'watch_gyro': processed_dataframe(pd.DataFrame(arff.loadarff(f\"arff_files/watch/gyro/data_{i}_gyro_watch.arff\")[0]), columns_to_be_dropped)\n",
    "} for i in range(1600, 1651) if i != 1614]  # person 1614 missing in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_combination = [[i]for i in sensors] + \\\n",
    "    [list(i) for i in list(combinations(sensors, 2))]+[sensors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biometry_models = {person['guid']:{activity: {'+'.join(combination): tuple[RandomForestClassifier,float] for combination in every_combination} for activity in activities } for person in people}\n",
    "# for person in people:\n",
    "#     impostors = pick_impostors(person['guid'], people)\n",
    "#     for activity in activities:\n",
    "#         for combination in every_combination:\n",
    "#             train, test = biometric_train_test_split(\n",
    "#                 person, impostors, activity, combination)\n",
    "#             if len(train) == 0 or len(test)==0:\n",
    "#                 continue\n",
    "#             train_target = train['class']\n",
    "#             train = train.drop(columns=['class'])\n",
    "#             test_target = test['class']\n",
    "#             test = test.drop(columns=['class'])\n",
    "#             biometry_classifier = RandomForestClassifier(\n",
    "#                 10, max_features=int(sqrt(len(train_target.columns))))\n",
    "#             classifier.fit(train, train_target)\n",
    "#             biometry_models[person['guid']][activity]['+'.join(combination)] = (biometry_classifier, compute_eer_from_paper(test_target,biometry_classifier.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people_models = {person['guid']: {'+'.join(combination): tuple[RandomForestClassifier, float]\n",
    "#                                   for combination in every_combination} for person in people}\n",
    "# kf = KFold(n_splits=10)\n",
    "# people_df = person_classification_df_builder(people, sensors)\n",
    "# people_target = people_df['class']\n",
    "# people_df = people_df.drop(columns=['class'])\n",
    "# people_classifier = RandomForestClassifier(10, max_features=int(sqrt(len(people_df.columns))))\n",
    "# # people_classifier.fit(people_df,people_target)\n",
    "# score = cross_validate(people_classifier,people_df,people_target,cv=kf,scoring='accuracy')\n",
    "# score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
